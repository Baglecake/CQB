conservative_model:
  name: 'Conservative-Model-Gemma-2-9B-AWQ'
  model_path: 'hugging-quants/gemma-2-9b-it-AWQ-INT4'
  quantization: 'awq_marlin'  # CHANGED: Use awq_marlin instead of awq
  dtype: 'bfloat16'
  memory_fraction: 0.4
  temperature: 0.2
  top_p: 0.7
  max_tokens: 1536
  max_model_len: 8192
  enforce_eager: false
  max_num_seqs: 2

innovative_model:
  name: 'Innovative-Model-Qwen3-8B'
  model_path: 'Qwen/Qwen3-8B'  # UPDATED: New Qwen3-8B model
  # quantization: removed - using base model
  dtype: 'bfloat16'  # UPDATED: Better precision for base model
  memory_fraction: 0.5  # UPDATED: Increased for larger unquantized model
  temperature: 0.8
  top_p: 0.7
  max_tokens: 1536
  max_model_len: 16384  # UPDATED: Qwen3 supports longer context
  enforce_eager: false
  max_num_seqs: 2

rounds:
  enable_subspecialist_consultation: true
  enable_preferential_voting: true
  enable_symptom_management: true
  
evaluation:
  clinical_recall_threshold: 0.85
  precision_threshold: 0.80
  
synthesis:
  enable_credibility_weighting: true
  enable_tempo_scoring: true